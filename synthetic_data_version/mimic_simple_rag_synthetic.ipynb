{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34afc256",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff2bbfe-2ee9-4a22-b704-30dc4fc53d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                        mimic_simple_rag_synthetic.ipynb\n",
      "admissions_data_generator.py     synthetic_admissions.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f504ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e82f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LangChain components\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ad2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FAISS for vector database\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d7f815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables (for OpenAI API key)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c0bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if OpenAI API key is available\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"Warning: OPENAI_API_KEY not found in environment variables.\")\n",
    "    print(\"Please set your OpenAI API key in .env file or directly in this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627d42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load synthetic admissions data\n",
    "synthetic_data = pd.read_csv(\"synthetic_admissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d02213ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 synthetic admission records\n"
     ]
    }
   ],
   "source": [
    "# Convert to text format\n",
    "data_texts = []\n",
    "data_metadata = []\n",
    "for _, row in synthetic_data.iterrows():\n",
    "    text_str = f\"Subject {row['subject_id']}, HADM {row['hadm_id']}, admitted on {row['admittime']}\"\n",
    "    data_texts.append(text_str)\n",
    "    metadata = {\n",
    "        \"subject_id\": row[\"subject_id\"],\n",
    "        \"hadm_id\": row[\"hadm_id\"],\n",
    "        \"admittime\": row[\"admittime\"]\n",
    "    }\n",
    "    data_metadata.append(metadata)\n",
    "print(f\"Loaded {len(data_texts)} synthetic admission records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbb0329e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define improved chunking with RecursiveCharacterTextSplitter\n",
    "def chunk_texts(texts, metadata, chunk_size=100, chunk_overlap=20):\n",
    "    \"\"\"Split texts into chunks with the specified size and overlap\"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \", \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_chunks = []\n",
    "    chunk_metadata = []\n",
    "    \n",
    "    for i, txt in enumerate(texts):\n",
    "        chunks = splitter.split_text(txt)\n",
    "        for chunk in chunks:\n",
    "            all_chunks.append(chunk)\n",
    "            # Copy metadata from the original text to each chunk\n",
    "            chunk_metadata.append(metadata[i])\n",
    "    \n",
    "    return all_chunks, chunk_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c38f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply chunking to our admission texts\n",
    "chunks, chunk_metadata = chunk_texts(data_texts, data_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5edb936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 20 chunks from 20 admission records\n",
      "\n",
      "The chunks:\n",
      "Chunk 1: Subject 2454, HADM 872390, admitted on 2024-06-10 14:13:22\n",
      "Chunk 2: Subject 5319, HADM 256217, admitted on 2024-11-12 14:13:22\n",
      "Chunk 3: Subject 4866, HADM 581271, admitted on 2024-08-08 14:13:22\n",
      "Chunk 4: Subject 1657, HADM 122498, admitted on 2024-11-21 14:13:22\n",
      "Chunk 5: Subject 3222, HADM 191836, admitted on 2024-05-29 14:13:22\n",
      "Chunk 6: Subject 3343, HADM 103309, admitted on 2024-12-10 14:13:22\n",
      "Chunk 7: Subject 4943, HADM 984392, admitted on 2024-10-29 14:13:22\n",
      "Chunk 8: Subject 3761, HADM 682863, admitted on 2025-01-28 14:13:22\n",
      "Chunk 9: Subject 3330, HADM 343504, admitted on 2025-02-10 14:13:22\n",
      "Chunk 10: Subject 2411, HADM 397528, admitted on 2024-06-09 14:13:22\n",
      "Chunk 11: Subject 7523, HADM 384362, admitted on 2024-03-14 14:13:22\n",
      "Chunk 12: Subject 4993, HADM 811660, admitted on 2024-06-03 14:13:22\n",
      "Chunk 13: Subject 1316, HADM 366414, admitted on 2024-09-02 14:13:22\n",
      "Chunk 14: Subject 7484, HADM 120955, admitted on 2024-10-30 14:13:22\n",
      "Chunk 15: Subject 1661, HADM 679196, admitted on 2024-07-28 14:13:22\n",
      "Chunk 16: Subject 9644, HADM 159958, admitted on 2024-08-13 14:13:22\n",
      "Chunk 17: Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22\n",
      "Chunk 18: Subject 9278, HADM 420114, admitted on 2024-06-12 14:13:22\n",
      "Chunk 19: Subject 2968, HADM 165341, admitted on 2024-05-13 14:13:22\n",
      "Chunk 20: Subject 9476, HADM 234012, admitted on 2024-09-17 14:13:22\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generated {len(chunks)} chunks from {len(data_texts)} admission records\")\n",
    "print(\"\\nThe chunks:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b877552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/3cgg344n60116_0p4_mxd5400000gn/T/ipykernel_69356/535464721.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the embedding model\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e50b41c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cached embeddings or generate new ones\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb27b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_embeddings = None\n",
    "if os.path.exists(\"embeddings_cache.pkl\"):\n",
    "    with open(\"embeddings_cache.pkl\", \"rb\") as f:\n",
    "        cached_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd875c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    }
   ],
   "source": [
    "if cached_embeddings is not None:\n",
    "    print(\"Loading embeddings from cache...\")\n",
    "    chunk_embeddings = cached_embeddings\n",
    "    print(f\"Loaded {len(chunk_embeddings)} embeddings from cache\")\n",
    "else:\n",
    "    print(\"Generating embeddings...\")\n",
    "    chunk_embeddings = embedder.embed_documents(chunks)\n",
    "    with open(\"embeddings_cache.pkl\", \"wb\") as f:\n",
    "        pickle.dump(chunk_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ae9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array for FAISS\n",
    "embeddings_array = np.array(chunk_embeddings).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e021620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FAISS index\n",
    "dimension = embeddings_array.shape[1]  # Get the embedding dimension\n",
    "index = faiss.IndexFlatL2(dimension)   # Using L2 distance for similarity\n",
    "index.add(embeddings_array)            # Add vectors to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a226ebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created FAISS index with 20 vectors of dimension 384\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created FAISS index with {index.ntotal} vectors of dimension {dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee296631",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample embedding values: [-0.0009614374139346182, 0.008348588831722736, 0.03792175278067589, 0.019212789833545685, 0.03785982355475426]...\n"
     ]
    }
   ],
   "source": [
    "# Show the first few values of the first embedding vector\n",
    "print(f\"\\nSample embedding values: {chunk_embeddings[0][:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8107c92b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define retrieval and generation functions\n",
    "def retrieve_with_faiss(query, index, chunks, metadata, top_k=3):\n",
    "    \"\"\"Retrieve relevant chunks using FAISS index\"\"\"\n",
    "    query_vector = np.array([embedder.embed_query(query)]).astype('float32')\n",
    "    \n",
    "    # Search the index\n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        if idx < len(chunks):  # Ensure index is valid\n",
    "            results.append({\n",
    "                \"chunk\": chunks[idx],\n",
    "                \"distance\": distances[0][i],\n",
    "                \"metadata\": metadata[idx] if idx < len(metadata) else {}\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e214265",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def answer_query(user_query, chunks, index, chunk_meta, chat_model, top_k=3):\n",
    "    \"\"\"Answer a query using RAG\"\"\"\n",
    "    results = retrieve_with_faiss(user_query, index, chunks, chunk_meta, top_k)\n",
    "    retrieved_context = \"\\n\".join([f\"- {r['chunk']}\" for r in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful medical assistant. Answer based only on the context provided.\"),\n",
    "        HumanMessage(content=f\"Context:\\n{retrieved_context}\\n\\nUser query: {user_query}\\nAnswer in a concise way:\")\n",
    "    ]\n",
    "    \n",
    "    response = chat_model.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"query\": user_query,\n",
    "        \"retrieved_contexts\": [r[\"chunk\"] for r in results],\n",
    "        \"relevance_scores\": [r[\"distance\"] for r in results],\n",
    "        \"answer\": response.content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7668f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/3cgg344n60116_0p4_mxd5400000gn/T/ipykernel_69356/290631747.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n"
     ]
    }
   ],
   "source": [
    "# Initialize chat model\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e24536fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries\n",
    "example_queries = [\n",
    "    \"Who was admitted in February 2139?\",\n",
    "    \"When was Subject 10348 admitted?\",\n",
    "    \"Are there any admissions from the 2180s?\",\n",
    "    \"Which patient has the most recent admission date?\",\n",
    "    \"How many subjects were admitted after 2150?\",\n",
    "    \"List all patients admitted in the year 2109\",\n",
    "    \"Was anyone admitted at night after 10 PM?\",\n",
    "    \"What's the earliest admission date in the dataset?\",\n",
    "    \"How many subjects have ID numbers below 5000?\",\n",
    "    \"Are there more admissions before or after 2150?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "748f71e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Who was admitted in February 2139?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 9278, HADM 420114, admitted on 2024-06-12 14:13:22 (distance: 0.7842)\n",
      "2. Subject 2454, HADM 872390, admitted on 2024-06-10 14:13:22 (distance: 0.8034)\n",
      "3. Subject 4993, HADM 811660, admitted on 2024-06-03 14:13:22 (distance: 0.8124)\n",
      "\n",
      "Answer: There is no information provided about any admissions in February 2139.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: When was Subject 10348 admitted?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22 (distance: 0.5706)\n",
      "2. Subject 2454, HADM 872390, admitted on 2024-06-10 14:13:22 (distance: 0.5904)\n",
      "3. Subject 3343, HADM 103309, admitted on 2024-12-10 14:13:22 (distance: 0.5912)\n",
      "\n",
      "Answer: There is no information provided about Subject 10348's admission date.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Are there any admissions from the 2180s?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22 (distance: 1.0331)\n",
      "2. Subject 2454, HADM 872390, admitted on 2024-06-10 14:13:22 (distance: 1.0944)\n",
      "3. Subject 4993, HADM 811660, admitted on 2024-06-03 14:13:22 (distance: 1.0996)\n",
      "\n",
      "Answer: No, there are no admissions from the 2180s based on the provided context.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Which patient has the most recent admission date?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22 (distance: 1.0931)\n",
      "2. Subject 7484, HADM 120955, admitted on 2024-10-30 14:13:22 (distance: 1.1365)\n",
      "3. Subject 4993, HADM 811660, admitted on 2024-06-03 14:13:22 (distance: 1.1404)\n",
      "\n",
      "Answer: Subject 7484, HADM 120955 has the most recent admission date.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: How many subjects were admitted after 2150?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22 (distance: 0.7787)\n",
      "2. Subject 2454, HADM 872390, admitted on 2024-06-10 14:13:22 (distance: 0.7887)\n",
      "3. Subject 3330, HADM 343504, admitted on 2025-02-10 14:13:22 (distance: 0.8099)\n",
      "\n",
      "Answer: Zero subjects were admitted after 2150 based on the provided context.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: List all patients admitted in the year 2109\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 2454, HADM 872390, admitted on 2024-06-10 14:13:22 (distance: 1.0907)\n",
      "2. Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22 (distance: 1.1087)\n",
      "3. Subject 3330, HADM 343504, admitted on 2025-02-10 14:13:22 (distance: 1.1467)\n",
      "\n",
      "Answer: There are no patients admitted in the year 2109 based on the provided context.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Was anyone admitted at night after 10 PM?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 7484, HADM 120955, admitted on 2024-10-30 14:13:22 (distance: 1.2158)\n",
      "2. Subject 3330, HADM 343504, admitted on 2025-02-10 14:13:22 (distance: 1.2305)\n",
      "3. Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22 (distance: 1.2478)\n",
      "\n",
      "Answer: Based on the provided context, no one was admitted at night after 10 PM.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: What's the earliest admission date in the dataset?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22 (distance: 1.0721)\n",
      "2. Subject 7484, HADM 120955, admitted on 2024-10-30 14:13:22 (distance: 1.1419)\n",
      "3. Subject 4993, HADM 811660, admitted on 2024-06-03 14:13:22 (distance: 1.1562)\n",
      "\n",
      "Answer: The earliest admission date in the dataset is 2024-06-03.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: How many subjects have ID numbers below 5000?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 3330, HADM 343504, admitted on 2025-02-10 14:13:22 (distance: 1.1591)\n",
      "2. Subject 7484, HADM 120955, admitted on 2024-10-30 14:13:22 (distance: 1.2036)\n",
      "3. Subject 4993, HADM 811660, admitted on 2024-06-03 14:13:22 (distance: 1.2240)\n",
      "\n",
      "Answer: Two subjects have ID numbers below 5000.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Query: Are there more admissions before or after 2150?\n",
      "\n",
      "Retrieved contexts:\n",
      "1. Subject 8602, HADM 829266, admitted on 2024-07-30 14:13:22 (distance: 1.1032)\n",
      "2. Subject 3343, HADM 103309, admitted on 2024-12-10 14:13:22 (distance: 1.1059)\n",
      "3. Subject 2454, HADM 872390, admitted on 2024-06-10 14:13:22 (distance: 1.1157)\n",
      "\n",
      "Answer: There are more admissions before 2150.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test each query\n",
    "for query in example_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    result = answer_query(query, chunks, index, chunk_metadata, chat)\n",
    "    print(\"\\nRetrieved contexts:\")\n",
    "    for i, context in enumerate(result[\"retrieved_contexts\"]):\n",
    "        print(f\"{i+1}. {context} (distance: {result['relevance_scores'][i]:.4f})\")\n",
    "    print(f\"\\nAnswer: {result['answer']}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
